# Observatorio AR-Telecom-2025 ENACOM# AR-Telecom-2025-Observatorio-ENACOM

Observatorio 2025 de telecom en Argentina con datos ENACOM: pipeline y dashboard para medir penetraci√≥n, velocidades y brechas por provincia (T1/2025)

Proyecto de an√°lisis de datos de telecomunicaciones en Argentina basado en datos p√∫blicos de ENACOM.

# AR-Telecom-2025 Observatorio ENACOM

## üéØ Objetivo

Proyecto de ciencia de datos para an√°lisis de telecomunicaciones en Argentina. Incluye ingesti√≥n, transformaci√≥n, validaci√≥n, visualizaci√≥n y machine learning.

Realizar an√°lisis exploratorio y ETL (Extract, Transform, Load) de los datos de telecomunicaciones de Argentina para generar insights sobre el sector.

## Conversi√≥n a CSV

## üìÅ Estructura del ProyectoConvertimos todos los archivos `.xlsx` ubicados en `data/raw/` a formato `.csv` en `data/raw/enacom/` para estandarizar el pipeline.



```Ejecutamos:

AR-Telecom-2025-Observatorio-ENACOM/```

‚îú‚îÄ‚îÄ data/python pipelines/exportamos_csv.py

‚îÇ   ‚îú‚îÄ‚îÄ raw/enacom/          # Datos originales en formato CSV```

‚îÇ   ‚îî‚îÄ‚îÄ processed/           # Datos limpios y transformados

‚îú‚îÄ‚îÄ notebooks/## Dataset procesado y diccionario

‚îÇ   ‚îî‚îÄ‚îÄ eda_etl_completo.ipynb    # An√°lisis exploratorio y ETLGeneramos dataset unificado y artefactos de documentaci√≥n:

‚îú‚îÄ‚îÄ pipelines/```

‚îÇ   ‚îî‚îÄ‚îÄ etl_principal.py     # Script principal de transformaci√≥npython pipelines/generamos_diccionario.py

‚îú‚îÄ‚îÄ tests/```

‚îÇ   ‚îî‚îÄ‚îÄ test_etl.py         # Tests b√°sicos de validaci√≥nEsto produce:

‚îú‚îÄ‚îÄ requirements.txt        # Dependencias del proyecto- `data/processed/datos_unificados.parquet`

‚îî‚îÄ‚îÄ README.md              # Este archivo- `docs/diccionario_datos.csv`

```- `docs/catalogo_valores.csv`



## üöÄ Inicio R√°pidoDesde el notebook `notebooks/etl.ipynb` tambi√©n exportamos un diccionario b√°sico (`docs/diccionario_datos_basico.csv`).



### 1. Instalaci√≥n de dependencias## Dimensiones y hechos iniciales

Creamos dimensiones base y un fact de accesos de internet:

```bash```

pip install -r requirements.txtpython pipelines/generamos_dimensiones.py

``````

Esto produce:

### 2. Ejecutar pipeline ETL- `data/processed/dim_tiempo.parquet`

- `data/processed/dim_provincia.parquet`

```bash- `data/processed/fact_internet_accesos.parquet`

python pipelines/etl_principal.py

```## Particionado por tecnolog√≠a (Wide -> Long)

Normalizamos las tecnolog√≠as de acceso (adsl, cablemodem, fibra_optica, wireless, otros) a formato largo y generamos:

### 3. Explorar datos```

python pipelines/generamos_particionado.py

Abrir y ejecutar el notebook:```

```bashSalidas:

jupyter notebook notebooks/eda_etl_completo.ipynb- `data/processed/dim_tecnologia.parquet`

```- `data/processed/fact_internet_accesos_tecnologia.parquet`

- Directorio particionado `data/processed/particionado_internet_accesos_tecnologias/` con subcarpetas `anio=YYYY/trimestre=T/`

## üìä Dominios de Datos

Este particionado permite queries selectivas por a√±o y trimestre sin leer todo el dataset completo, optimizando futuros an√°lisis y cargas a motores tipo DuckDB / Spark.

Los datos incluyen los siguientes dominios:

## Pipelines principales

- **Internet**: Accesos, penetraci√≥n, tecnolog√≠as, velocidades e ingresos- `pipelines/cargamos_enacom.py`

- **Telefon√≠a Fija**: Accesos, penetraci√≥n e ingresos  - `pipelines/limpiamos_datos.py`

- **Televisi√≥n**: Accesos, penetraci√≥n e ingresos- `pipelines/elaboramos_curacion.py`

- **Comunicaciones M√≥viles**: Accesos, llamadas, minutos, SMS, penetraci√≥n- `pipelines/preparamos_ml.py`

- **Mercado Postal**: Facturaci√≥n, producci√≥n, personal ocupado- `pipelines/exportamos_csv.py`

- **Portabilidad**: Datos de portabilidad m√≥vil- `pipelines/generamos_diccionario.py`

- `pipelines/generamos_dimensiones.py`

## üîÑ Proceso ETL

## Reproducibilidad

### Extracci√≥n```

- Lectura de archivos CSV desde `data/raw/enacom/`python -m venv venv

- Manejo de errores de codificaci√≥n y formato./venv/Scripts/Activate.ps1

pip install -r requirements.txt

### Transformaci√≥npython pipelines/exportamos_csv.py

- Normalizaci√≥n de nombres de columnas a snake_casepython pipelines/generamos_diccionario.py

- Limpieza de datos b√°sica (tipos, valores nulos)python pipelines/generamos_dimensiones.py

- Normalizaci√≥n de nombres de provinciaspython pipelines/generamos_particionado.py

- Conversi√≥n de tipos de datos apropiadospython pipelines/exportamos_unificado_csv.py

```

### Carga

- Guardado de datos limpios en `data/processed/`## Exportar dataset unificado a CSV (comprimido)

- Generaci√≥n de archivo de resumen con metadatosPara compartir el dataset unificado en formato tabular ligero:

```

## üìà An√°lisis Disponiblespython pipelines/exportamos_unificado_csv.py

```

El notebook `eda_etl_completo.ipynb` incluye:Genera:

- `data/processed/datos_unificados.csv.gz` (mismas columnas que el parquet)

1. **Configuraci√≥n del entorno**

2. **Exploraci√≥n del directorio raw**Ventajas: interoperabilidad (BI externo, hojas de c√°lculo). Para an√°lisis interno preferir parquet.

3. **Carga e inspecci√≥n inicial**

4. **Proceso ETL completo**## Dataset Light (√∫ltimos 4 trimestres)

5. **An√°lisis exploratorio de datos (EDA)**Para acelerar el dashboard se genera una versi√≥n reducida:

6. **Visualizaciones**```

7. **An√°lisis estad√≠stico descriptivo**python pipelines/exportamos_unificado_light.py

8. **Detecci√≥n de valores at√≠picos**```

9. **An√°lisis de correlaciones**Produce:

10. **Guardado de datos procesados**- `data/processed/datos_unificados_light.parquet`

- `data/processed/datos_unificados_light.csv.gz`

## üß™ Tests

Uso en Streamlit: la p√°gina `Home.py` detecta y muestra KPIs si existe el parquet light. Si no, mostrar√° una advertencia con el comando necesario.

Ejecutar tests de validaci√≥n:

```bash
python -m pytest tests/
```

## üìã Dependencias Principales

- `pandas`: Manipulaci√≥n de datos
- `numpy`: C√°lculos num√©ricos
- `matplotlib`: Visualizaciones b√°sicas
- `seaborn`: Visualizaciones estad√≠sticas
- `jupyter`: Entorno de notebooks

## ü§ù Contribuir

1. Fork del repositorio
2. Crear rama para nueva funcionalidad
3. Realizar cambios y tests
4. Crear pull request

## üìÑ Licencia

Este proyecto est√° bajo licencia MIT. Ver archivo LICENSE para detalles.

## üîó Fuente de Datos

Los datos provienen de ENACOM (Ente Nacional de Comunicaciones) de Argentina:
- Sitio web: https://www.enacom.gob.ar/
- Datos abiertos y estad√≠sticas oficiales del sector telecomunicaciones

## üìû Contacto

Para consultas sobre el proyecto, abrir un issue en GitHub.